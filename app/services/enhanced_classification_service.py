# app/services/enhanced_classification_service.py
import re
import pandas as pd
from typing import List, Dict, Any, Tuple
from datetime import datetime
import numpy as np
from collections import Counter

class EnhancedClassificationService:
    """
    í†µí•© ê±°ë˜ ë¶„ë¥˜ ë° ë¶„ì„ ì„œë¹„ìŠ¤
    CSV/Excel íŒŒì¼ ì—…ë¡œë“œë¶€í„° ê³ ë„í™”ëœ ë¶„ë¥˜ê¹Œì§€ ì›ìŠ¤í†± ì²˜ë¦¬
    """
    
    def __init__(self):
        # ê¸°ë³¸ ì¹´í…Œê³ ë¦¬ ë§¤í•‘ (NHë†í˜‘ ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ í™•ì¥)
        self.CATEGORY_PATTERNS = {
            "ì‹ë¹„": {
                "exact_matches": ["ë§¥ë„ë‚ ë“œ", "ë²„ê±°í‚¹", "ë¡¯ë°ë¦¬ì•„", "ìŠ¤íƒ€ë²…ìŠ¤", "ì´ë””ì•¼", "íˆ¬ì¸í”Œë ˆì´ìŠ¤", "íŒŒë¦¬ë°”ê²Œëœ¨"],
                "contains": ["ì‹ë‹¹", "ìŒì‹ì ", "ì¹´í˜", "ì»¤í”¼", "ì¹˜í‚¨", "í”¼ì", "ë„ì‹œë½", "ê¹€ë°¥", "ë¶„ì‹", "ì¡±ë°œ", "ë³´ìŒˆ", "ì‚¼ê²¹ì‚´", "ì¹´ì¹´ì˜¤í˜ì´", "ë‹¤ëª¨ë°ì´í† ", "ì´ìˆœë¡€", "SOOP"],
                "patterns": [r".*[í•œì¤‘ì¼ì–‘]ì‹.*", r".*ì¹˜í‚¨.*", r".*í”¼ì.*", r".*ì¹´í˜.*", r".*ì»¤í”¼.*"],
                "exclude": ["ì»¤í”¼ë¨¸ì‹ ", "ì»¤í”¼ì›ë‘"]
            },
            "êµí†µë¹„": {
                "exact_matches": ["ì¹´ì¹´ì˜¤íƒì‹œ", "ìš°ë²„", "íƒ€ë‹¤"],
                "contains": ["íƒì‹œ", "ë²„ìŠ¤", "ì§€í•˜ì² ", "ì£¼ìœ ì†Œ", "SKì—ë„ˆì§€", "GSì¹¼í…ìŠ¤", "S-OIL", "í˜„ëŒ€ì˜¤ì¼ë±…í¬", "íŒŒë€í•´ì¶©", "ì¼€ì´ë±…í¬"],
                "patterns": [r".*ì£¼ìœ .*", r".*íƒì‹œ.*", r".*ë²„ìŠ¤.*", r".*ì² ë„.*"],
                "exclude": []
            },
            "ì£¼ê±°ë¹„": {
                "exact_matches": ["í•œêµ­ì „ë ¥ê³µì‚¬", "ì„œìš¸ë„ì‹œê°€ìŠ¤", "ì¸ì²œë„ì‹œê°€ìŠ¤"],
                "contains": ["ì „ë ¥", "ê°€ìŠ¤", "ìˆ˜ë„", "ê´€ë¦¬ì‚¬ë¬´ì†Œ", "ì•„íŒŒíŠ¸", "ë¹Œë¼", "ì›ë£¸"],
                "patterns": [r".*ì „ë ¥.*", r".*ê°€ìŠ¤.*", r".*ìˆ˜ë„.*", r".*ê´€ë¦¬ë¹„.*"],
                "exclude": []
            },
            "í†µì‹ ë¹„": {
                "exact_matches": ["SKT", "KT", "LGU+"],
                "contains": ["í†µì‹ ", "í…”ë ˆì½¤", "ì¸í„°ë„·", "íœ´ëŒ€í°", "í•¸ë“œí°"],
                "patterns": [r"SK.*í†µì‹ .*", r"KT.*", r"LG.*í†µì‹ .*"],
                "exclude": []
            },
            "ì˜ë£Œë¹„": {
                "exact_matches": [],
                "contains": ["ë³‘ì›", "ì˜ì›", "í´ë¦¬ë‹‰", "ì¹˜ê³¼", "í•œì˜ì›", "ì•½êµ­", "ì •í˜•ì™¸ê³¼", "ë‚´ê³¼", "í”¼ë¶€ê³¼"],
                "patterns": [r".*ë³‘ì›.*", r".*ì˜ì›.*", r".*ì¹˜ê³¼.*", r".*ì•½êµ­.*"],
                "exclude": []
            },
            "êµìœ¡ë¹„": {
                "exact_matches": [],
                "contains": ["í•™ì›", "êµìŠµì†Œ", "ê³¼ì™¸", "ì–´í•™ì›", "í•™êµ", "ëŒ€í•™êµ"],
                "patterns": [r".*í•™ì›.*", r".*êµìœ¡.*", r".*í•™ìŠµ.*"],
                "exclude": []
            },
            "ìƒí™œìš©í’ˆë¹„": {
                "exact_matches": ["ì´ë§ˆíŠ¸", "ë¡¯ë°ë§ˆíŠ¸", "í™ˆí”ŒëŸ¬ìŠ¤", "ì½”ìŠ¤íŠ¸ì½”", "GS25", "CU", "ì„¸ë¸ì¼ë ˆë¸"],
                "contains": ["ë§ˆíŠ¸", "í¸ì˜ì ", "ìŠˆí¼", "ëŒ€í˜•ë§ˆíŠ¸", "í•˜ì´í¼ë§ˆì¼“"],
                "patterns": [r".*ë§ˆíŠ¸.*", r".*í¸ì˜ì .*"],
                "exclude": []
            },
            "ì´ë¯¸ìš©/í™”ì¥í’ˆ": {
                "exact_matches": [],
                "contains": ["ë¯¸ìš©ì‹¤", "í—¤ì–´ìƒµ", "ë„¤ì¼", "í”¼ë¶€ê´€ë¦¬ì‹¤", "í™”ì¥í’ˆ", "ì½”ìŠ¤ë©”í‹±"],
                "patterns": [r".*ë¯¸ìš©.*", r".*í—¤ì–´.*", r".*ë·°í‹°.*"],
                "exclude": []
            },
            "ì—¬ê°€ë¹„": {
                "exact_matches": ["CGV", "ë¡¯ë°ì‹œë„¤ë§ˆ", "ë©”ê°€ë°•ìŠ¤"],
                "contains": ["ì˜í™”ê´€", "ë…¸ë˜ë°©", "PCë°©", "ë‹¹êµ¬ì¥", "ë³¼ë§ì¥", "í—¬ìŠ¤ì¥", "í”¼íŠ¸ë‹ˆìŠ¤"],
                "patterns": [r".*PCë°©.*", r".*ë…¸ë˜ë°©.*", r".*í—¬ìŠ¤.*"],
                "exclude": []
            }
        }
        
        # ê±°ë˜ íŒ¨í„´ ë¶„ì„ì„ ìœ„í•œ ì •ê·œì‹
        self.TRANSACTION_PATTERNS = {
            "ì˜¨ë¼ì¸ì‡¼í•‘": [r".*ì˜¨ë¼ì¸.*", r".*ì¸í„°ë„·.*", r".*ì‡¼í•‘ëª°.*", r".*11ë²ˆê°€.*", r".*ì¿ íŒ¡.*", r".*ì˜¥ì…˜.*"],
            "ë°°ë‹¬ì£¼ë¬¸": [r".*ë°°ë‹¬.*", r".*ìš”ê¸°ìš”.*", r".*ë°°ë¯¼.*", r".*ë”œë¦¬ë²„ë¦¬.*"],
            "ì •ê¸°ê²°ì œ": [r".*êµ¬ë….*", r".*ì›”ì •ì•¡.*", r".*ìë™ê²°ì œ.*", r".*ë©¤ë²„ì‹­.*"],
            "í˜„ê¸ˆì¸ì¶œ": [r".*ATM.*", r".*í˜„ê¸ˆì¸ì¶œ.*", r".*ì¶œê¸ˆ.*"],
            "ê³„ì¢Œì´ì²´": [r".*ì´ì²´.*", r".*ì†¡ê¸ˆ.*", r".*ì…ê¸ˆ.*"]
        }
        
        self.model_initialized = False
    
    def initialize_model(self):
        """ê³ ë„í™”ëœ ë¶„ë¥˜ ëª¨ë¸ ì´ˆê¸°í™”"""
        if not self.model_initialized:
            print("ğŸš€ í†µí•© ë¶„ë¥˜ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
            self.model_initialized = True
    
    def analyze_file_structure(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        CSV/Excel íŒŒì¼ êµ¬ì¡° ìë™ ë¶„ì„
        
        Args:
            df: íŒŒì‹±ëœ DataFrame
            
        Returns:
            Dict: íŒŒì¼ êµ¬ì¡° ë¶„ì„ ê²°ê³¼
        """
        analysis = {
            "total_rows": len(df),
            "total_columns": len(df.columns),
            "columns": list(df.columns),
            "detected_columns": {},
            "data_quality": {},
            "recommendations": []
        }
        
        # ì»¬ëŸ¼ íƒ€ì… ìë™ ê°ì§€
        column_mapping = {
            "date": ["ë‚ ì§œ", "ê±°ë˜ì¼", "ê±°ë˜ì¼ì‹œ", "ì¼ì", "date", "transaction_date"],
            "amount": ["ê¸ˆì•¡", "ì¶œê¸ˆì•¡", "ì…ê¸ˆì•¡", "ì¶œê¸ˆê¸ˆì•¡", "ì…ê¸ˆê¸ˆì•¡", "ì‚¬ìš©ê¸ˆì•¡", "ê²°ì œê¸ˆì•¡", "amount", "price"],
            "merchant": ["ê°€ë§¹ì ", "ê°€ë§¹ì ëª…", "ìƒí˜¸ëª…", "ì ìš”", "ê±°ë˜ì²˜", "ìƒì ëª…", "merchant", "store"],
            "description": ["ê±°ë˜ê¸°ë¡ì‚¬í•­", "ë‚´ì—­", "ì„¤ëª…", "ë¹„ê³ ", "ë©”ëª¨", "description", "memo"],
            "category": ["ì¹´í…Œê³ ë¦¬", "ë¶„ë¥˜", "category", "type"],
            "payment_method": ["ê²°ì œìˆ˜ë‹¨", "ê²°ì œë°©ë²•", "ì¹´ë“œ", "í˜„ê¸ˆ", "payment_method"]
        }
        
        # ì¼ë°˜ì ì¸ ì»¬ëŸ¼ ë§¤ì¹­
        for col_type, keywords in column_mapping.items():
            for col in df.columns:
                col_str = str(col).strip()
                col_lower = col_str.lower()
                
                for keyword in keywords:
                    if keyword.lower() in col_lower:
                        analysis["detected_columns"][col_type] = col_str
                        print(f"âœ… {col_type} ì»¬ëŸ¼ ë°œê²¬: '{col_str}' (í‚¤ì›Œë“œ: '{keyword}')")
                        break
                if col_type in analysis["detected_columns"]:
                    break
        
        # ë°ì´í„° í’ˆì§ˆ ë¶„ì„
        for col in df.columns:
            null_count = df[col].isnull().sum()
            unique_count = df[col].nunique()
            
            analysis["data_quality"][col] = {
                "null_count": int(null_count),
                "null_percentage": round((null_count / len(df)) * 100, 2),
                "unique_count": int(unique_count),
                "sample_values": df[col].dropna().head(3).tolist()
            }
        
        # ê¶Œì¥ì‚¬í•­ ìƒì„±
        if "amount" not in analysis["detected_columns"]:
            analysis["recommendations"].append("âš ï¸ ê¸ˆì•¡ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ ì§€ì •í•´ì£¼ì„¸ìš”.")
        
        if "merchant" not in analysis["detected_columns"]:
            analysis["recommendations"].append("âš ï¸ ê°€ë§¹ì ëª… ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±°ë˜ê¸°ë¡ì‚¬í•­ ì»¬ëŸ¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
        # ë””ë²„ê¹… ì •ë³´ ì¶œë ¥
        print("ğŸ” ë””ë²„ê¹…: ê°ì§€ëœ ëª¨ë“  ì»¬ëŸ¼:")
        for i, col in enumerate(df.columns):
            print(f"  {i}: '{col}' (íƒ€ì…: {type(col)})")

        print("ğŸ” ë””ë²„ê¹…: ì»¬ëŸ¼ ë§¤ì¹­ ê²°ê³¼:")
        for col_type, detected_col in analysis["detected_columns"].items():
            print(f"  {col_type}: '{detected_col}'")

        return analysis
    
    def extract_merchant_from_description(self, description: str) -> str:
        """
        ê±°ë˜ê¸°ë¡ì‚¬í•­ì—ì„œ ê°€ë§¹ì ëª… ì¶”ì¶œ
        
        Args:
            description: ê±°ë˜ê¸°ë¡ì‚¬í•­ í…ìŠ¤íŠ¸
            
        Returns:
            str: ì¶”ì¶œëœ ê°€ë§¹ì ëª…
        """
        if not description or pd.isna(description):
            return "ë¯¸ìƒ"
        
        desc = str(description).strip()
        
        # ì¼ë°˜ì ì¸ ê±°ë˜ê¸°ë¡ì‚¬í•­ íŒ¨í„´ë“¤
        patterns = [
            # "ìŠ¹ì¸ ê°€ë§¹ì ëª… 1234" í˜•íƒœ
            r'ìŠ¹ì¸\s+([ê°€-í£A-Za-z0-9\s]+?)\s+\d+',
            # "ì¹´ë“œê²°ì œ ê°€ë§¹ì ëª…" í˜•íƒœ  
            r'ì¹´ë“œê²°ì œ\s+([ê°€-í£A-Za-z0-9\s]+?)(?:\s|$)',
            # "ì²´í¬ê²°ì œ ê°€ë§¹ì ëª…" í˜•íƒœ
            r'ì²´í¬ê²°ì œ\s+([ê°€-í£A-Za-z0-9\s]+?)(?:\s|$)',
            # "ê°„í¸ê²°ì œ ê°€ë§¹ì ëª…" í˜•íƒœ
            r'ê°„í¸ê²°ì œ\s+([ê°€-í£A-Za-z0-9\s]+?)(?:\s|$)',
            # ì¼ë°˜ì ì¸ í•œê¸€ ìƒí˜¸ëª… (2ê¸€ì ì´ìƒ)
            r'([ê°€-í£]{2,}(?:[ê°€-í£A-Za-z0-9\s]*[ê°€-í£A-Za-z0-9])?)',
            # ì˜ë¬¸ ë¸Œëœë“œëª…
            r'([A-Za-z]{3,}(?:\s+[A-Za-z]+)*)'
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, desc)
            if matches:
                merchant = matches[0].strip()
                # ë„ˆë¬´ ì§§ê±°ë‚˜ ìˆ«ìë§Œ ìˆëŠ” ê²½ìš° ì œì™¸
                if len(merchant) >= 2 and not merchant.isdigit():
                    # ë¶ˆí•„ìš”í•œ ì ‘ë¯¸ì‚¬ ì œê±°
                    merchant = re.sub(r'(ì£¼ì‹íšŒì‚¬|ãˆœ|\(ì£¼\)|LTD|CO\.|INC)$', '', merchant).strip()
                    return merchant
        
        # íŒ¨í„´ ë§¤ì¹­ ì‹¤íŒ¨ì‹œ ì›ë³¸ì—ì„œ ì˜ë¯¸ìˆëŠ” ë¶€ë¶„ ì¶”ì¶œ
        cleaned = re.sub(r'[^\wê°€-í£\s]', ' ', desc)
        words = [w.strip() for w in cleaned.split() if len(w.strip()) >= 2]
        
        if words:
            return words[0]
        
        return desc[:20] if len(desc) > 20 else desc
    
    def advanced_categorize(self, merchant_name: str, description: str = "", amount: float = 0) -> Dict[str, Any]:
        """
        ê³ ë„í™”ëœ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ (ë‹¤ì¤‘ ì •ë³´ í™œìš©)
        
        Args:
            merchant_name: ê°€ë§¹ì ëª…
            description: ê±°ë˜ê¸°ë¡ì‚¬í•­
            amount: ê±°ë˜ê¸ˆì•¡
            
        Returns:
            Dict: ë¶„ë¥˜ ê²°ê³¼ ë° ì‹ ë¢°ë„
        """
        if not merchant_name or str(merchant_name).strip() == '':
            return {"category": "ê¸°íƒ€", "confidence": 0, "method": "default"}
        
        merchant = str(merchant_name).lower().strip()
        desc = str(description).lower().strip() if description else ""
        
        # 1ì°¨: ì •í™•í•œ ë§¤ì¹­
        for category, patterns in self.CATEGORY_PATTERNS.items():
            # ì •í™•í•œ ì´ë¦„ ë§¤ì¹­
            for exact in patterns["exact_matches"]:
                if exact.lower() in merchant:
                    return {"category": category, "confidence": 95, "method": "exact_match", "matched": exact}
            
            # ì œì™¸ í‚¤ì›Œë“œ ì²´í¬
            if any(exclude.lower() in merchant for exclude in patterns["exclude"]):
                continue
            
            # í¬í•¨ í‚¤ì›Œë“œ ë§¤ì¹­
            for keyword in patterns["contains"]:
                if keyword.lower() in merchant or keyword.lower() in desc:
                    return {"category": category, "confidence": 85, "method": "keyword_match", "matched": keyword}
            
            # ì •ê·œì‹ íŒ¨í„´ ë§¤ì¹­
            for pattern in patterns["patterns"]:
                if re.search(pattern, merchant) or re.search(pattern, desc):
                    return {"category": category, "confidence": 75, "method": "pattern_match", "matched": pattern}
        
        # 2ì°¨: ê¸ˆì•¡ ê¸°ë°˜ ì¶”ë¡  (íŠ¹ì • íŒ¨í„´ë“¤)
        if amount > 0:
            if 10000 <= amount <= 50000 and any(word in merchant for word in ["ì£¼ìœ ", "ê¸°ë¦„", "gas"]):
                return {"category": "êµí†µë¹„", "confidence": 70, "method": "amount_inference"}
            
            if amount >= 100000 and any(word in merchant for word in ["ì „ë ¥", "ê°€ìŠ¤", "ê´€ë¦¬"]):
                return {"category": "ì£¼ê±°ë¹„", "confidence": 70, "method": "amount_inference"}
            
            if 3000 <= amount <= 15000 and any(word in merchant for word in ["í¸ì˜ì ", "gs25", "cu", "ì„¸ë¸"]):
                return {"category": "ìƒí™œìš©í’ˆë¹„", "confidence": 70, "method": "amount_inference"}
        
        # 3ì°¨: ê±°ë˜ íŒ¨í„´ ë¶„ì„
        full_text = f"{merchant} {desc}"
        for pattern_type, patterns in self.TRANSACTION_PATTERNS.items():
            for pattern in patterns:
                if re.search(pattern, full_text):
                    if pattern_type == "ì˜¨ë¼ì¸ì‡¼í•‘":
                        return {"category": "ìƒí™œìš©í’ˆë¹„", "confidence": 60, "method": "transaction_pattern"}
                    elif pattern_type == "ë°°ë‹¬ì£¼ë¬¸":
                        return {"category": "ì‹ë¹„", "confidence": 80, "method": "transaction_pattern"}
        
        return {"category": "ê¸°íƒ€", "confidence": 0, "method": "unclassified"}
    
    def process_transactions_with_analysis(self, df: pd.DataFrame, file_structure: Dict) -> Dict[str, Any]:
        """
        ê±°ë˜ ë°ì´í„° ì²˜ë¦¬ ë° ê³ ë„í™”ëœ ë¶„ì„
        
        Args:
            df: ê±°ë˜ ë°ì´í„° DataFrame
            file_structure: íŒŒì¼ êµ¬ì¡° ë¶„ì„ ê²°ê³¼
            
        Returns:
            Dict: ì²˜ë¦¬ëœ ê±°ë˜ ë°ì´í„° ë° ë¶„ì„ ê²°ê³¼
        """
        detected_cols = file_structure["detected_columns"]
        
        # NHë†í˜‘ íŒŒì¼ íŠ¹ë³„ ì²˜ë¦¬: ì»¬ëŸ¼ëª…ì´ Unnamedì¸ ê²½ìš° ìë™ ë§¤í•‘
        if not detected_cols.get("amount") and any("Unnamed" in str(col) for col in df.columns):
            print("ğŸ”§ NHë†í˜‘ íŒŒì¼ íŠ¹ë³„ ì²˜ë¦¬ ëª¨ë“œ í™œì„±í™”")
            
            # ë°ì´í„°ì—ì„œ ì‹¤ì œ ê°’ë“¤ì„ í™•ì¸í•˜ì—¬ ì»¬ëŸ¼ ì¶”ì •
            for idx, col in enumerate(df.columns):
                sample_values = df[col].dropna().head(5).tolist()
                print(f"ì»¬ëŸ¼ {idx} ({col}) ìƒ˜í”Œ: {sample_values}")
                
                # ê¸ˆì•¡ ì»¬ëŸ¼ ì°¾ê¸° (ìˆ«ìì´ê³  1000 ì´ìƒì¸ ê°’ë“¤ì´ ë§ì€ ì»¬ëŸ¼)
                numeric_values = []
                for val in sample_values:
                    try:
                        # ì‰¼í‘œ ì œê±° í›„ ìˆ«ì ë³€í™˜ ì‹œë„
                        val_str = str(val).replace(",", "").strip()
                        if val_str and val_str != 'nan':
                            num_val = float(val_str)
                            if num_val > 0:
                                numeric_values.append(num_val)
                    except (ValueError, TypeError):
                        pass
                
                # ìœ íš¨í•œ ê¸ˆì•¡ ë°ì´í„°ê°€ ìˆê³ , 1000 ì´ìƒì˜ ê°’ì´ ìˆìœ¼ë©´ ê¸ˆì•¡ ì»¬ëŸ¼ìœ¼ë¡œ ì¶”ì •
                if len(numeric_values) >= 2 and any(v >= 1000 for v in numeric_values):
                    detected_cols["amount"] = col
                    print(f"âœ… ê¸ˆì•¡ ì»¬ëŸ¼ìœ¼ë¡œ ì¶”ì •: {col} (ìƒ˜í”Œ: {numeric_values})")
                    break
            
            # ê°€ë§¹ì ëª…/ê±°ë˜ê¸°ë¡ì‚¬í•­ ì»¬ëŸ¼ ì°¾ê¸° (í•œê¸€ì´ í¬í•¨ëœ í…ìŠ¤íŠ¸ ì»¬ëŸ¼)
            if not detected_cols.get("description"):
                for idx, col in enumerate(df.columns):
                    sample_values = df[col].dropna().head(5).tolist()
                    korean_count = 0
                    for val in sample_values:
                        val_str = str(val)
                        if re.search(r'[ê°€-í£]', val_str) and len(val_str) >= 2:
                            korean_count += 1
                    
                    if korean_count >= 2:
                        detected_cols["description"] = col
                        detected_cols["merchant"] = col  # ê°™ì€ ì»¬ëŸ¼ì—ì„œ ê°€ë§¹ì ëª… ì¶”ì¶œ
                        print(f"âœ… ê±°ë˜ê¸°ë¡ì‚¬í•­ ì»¬ëŸ¼ìœ¼ë¡œ ì¶”ì •: {col}")
                        break
        
        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        amount_col = detected_cols.get("amount")
        merchant_col = detected_cols.get("merchant")
        description_col = detected_cols.get("description")
        date_col = detected_cols.get("date")
        
        if not amount_col:
            raise ValueError("ê¸ˆì•¡ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        processed_transactions = []
        classification_stats = Counter()
        confidence_distribution = Counter()
        amount_by_category = {}
        
        for index, row in df.iterrows():
            try:
                # ê¸ˆì•¡ íŒŒì‹±
                amount_str = str(row[amount_col]).replace(",", "").replace(" ", "").strip()
                if pd.isna(row[amount_col]) or amount_str == '' or amount_str == 'nan':
                    continue
                
                amount = 0
                try:
                    amount = float(re.sub(r'[^\d.]', '', amount_str))
                except (ValueError, TypeError):
                    continue
                
                if amount <= 0:
                    continue
                
                # ê°€ë§¹ì ëª… ì¶”ì¶œ
                merchant_name = "ë¯¸ìƒ"
                if merchant_col and pd.notna(row[merchant_col]):
                    merchant_name = str(row[merchant_col]).strip()
                elif description_col and pd.notna(row[description_col]):
                    merchant_name = self.extract_merchant_from_description(str(row[description_col]))
                
                # ê±°ë˜ê¸°ë¡ì‚¬í•­
                description = ""
                if description_col and pd.notna(row[description_col]):
                    description = str(row[description_col])
                
                # ë‚ ì§œ íŒŒì‹±
                transaction_date = datetime.now()
                if date_col and pd.notna(row[date_col]):
                    try:
                        transaction_date = pd.to_datetime(row[date_col])
                    except:
                        pass
                
                # ê³ ë„í™”ëœ ë¶„ë¥˜
                classification_result = self.advanced_categorize(merchant_name, description, amount)
                category = classification_result["category"]
                confidence = classification_result["confidence"]
                
                # í†µê³„ ì—…ë°ì´íŠ¸
                classification_stats[category] += 1
                confidence_range = f"{(confidence//10)*10}-{(confidence//10)*10+9}%"
                confidence_distribution[confidence_range] += 1
                
                if category not in amount_by_category:
                    amount_by_category[category] = 0
                amount_by_category[category] += amount
                
                transaction = {
                    "transaction_date": transaction_date.isoformat() if hasattr(transaction_date, 'isoformat') else str(transaction_date),
                    "amount": amount,
                    "store_name": merchant_name,
                    "category": category,
                    "description": description,
                    "payment_method": "ì¹´ë“œ",
                    "classification_confidence": confidence,
                    "classification_method": classification_result["method"],
                    "matched_keyword": classification_result.get("matched", "")
                }
                
                processed_transactions.append(transaction)
                
            except Exception as e:
                print(f"í–‰ {index} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
        
        # ê³ ë„í™”ëœ ë¶„ì„ ê²°ê³¼
        total_amount = sum(amount_by_category.values()) if amount_by_category else 0
        
        analysis_result = {
            "total_transactions": len(processed_transactions),
            "total_amount": total_amount,
            "category_breakdown": {
                cat: {
                    "count": classification_stats[cat],
                    "amount": amount_by_category.get(cat, 0),
                    "percentage": round((amount_by_category.get(cat, 0) / total_amount) * 100, 2) if total_amount > 0 else 0
                }
                for cat in classification_stats.keys()
            },
            "classification_quality": {
                "high_confidence": sum(1 for t in processed_transactions if t["classification_confidence"] >= 80),
                "medium_confidence": sum(1 for t in processed_transactions if 60 <= t["classification_confidence"] < 80),
                "low_confidence": sum(1 for t in processed_transactions if t["classification_confidence"] < 60),
                "confidence_distribution": dict(confidence_distribution)
            },
            "unclassified_analysis": {
                "count": classification_stats.get("ê¸°íƒ€", 0),
                "percentage": round((classification_stats.get("ê¸°íƒ€", 0) / len(processed_transactions)) * 100, 2) if processed_transactions else 0,
                "top_unclassified": [
                    t["store_name"] for t in processed_transactions 
                    if t["category"] == "ê¸°íƒ€" and t["classification_confidence"] == 0
                ][:10]
            }
        }
        
        return {
            "transactions": processed_transactions,
            "analysis": analysis_result,
            "recommendations": self._generate_recommendations(analysis_result)
        }
    
    def _generate_recommendations(self, analysis: Dict) -> List[str]:
        """ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        unclassified_pct = analysis["unclassified_analysis"]["percentage"]
        if unclassified_pct > 20:
            recommendations.append(f"âš ï¸ ê¸°íƒ€ë¡œ ë¶„ë¥˜ëœ ê±°ë˜ê°€ {unclassified_pct}%ë¡œ ë†’ìŠµë‹ˆë‹¤. ì¶”ê°€ í‚¤ì›Œë“œ ë“±ë¡ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
        
        quality = analysis["classification_quality"]
        total_transactions = analysis["total_transactions"]
        if total_transactions > 0:
            low_confidence_pct = round((quality["low_confidence"] / total_transactions) * 100, 2)
            if low_confidence_pct > 30:
                recommendations.append(f"ğŸ“Š ë‚®ì€ ì‹ ë¢°ë„ ë¶„ë¥˜({low_confidence_pct}%)ê°€ ë§ìŠµë‹ˆë‹¤. ê±°ë˜ê¸°ë¡ì‚¬í•­ í’ˆì§ˆ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # ì¹´í…Œê³ ë¦¬ë³„ ì´ìƒ íŒ¨í„´ ê°ì§€
        for category, data in analysis["category_breakdown"].items():
            if data["percentage"] > 50:
                recommendations.append(f"ğŸ’¡ '{category}' ì¹´í…Œê³ ë¦¬ê°€ ì „ì²´ì˜ {data['percentage']}%ë¥¼ ì°¨ì§€í•©ë‹ˆë‹¤. ì„¸ë¶€ ë¶„ë¥˜ë¥¼ ê³ ë ¤í•´ë³´ì„¸ìš”.")
        
        return recommendations

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
enhanced_classification_service = EnhancedClassificationService()